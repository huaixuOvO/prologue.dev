---
title: 对数据要素和生成式AI的思考
publishDate: 2024-01-21
lastmod: 2024-01-28
description: 中国的“数据要素”政策是市场寻租的体现，生成式AI造成了搜索引擎污染以及语言的标准化。
---

## 数据要素

最近某位北大经济学教授声称“数据”是继土地、劳动力、资本、技术以外的新生产要素，“是我国首次提出的重大理论创新”，随之国家数据局印发《“数据要素×”三年行动计划（2024—2026年）》，这位北大教授居然说数据能直接创造价值，纵观世界众多经济学家，不会是这位教授发现了新古典经济学家Robert Solow没能发现的生产要素吧？将“数据赋能”作为经济增长的驱动力，在笔者看来这是因不懂得生成式AI的原理但又尽力模仿西方创新发展的滑稽场景，甚至将数据描述成能够市场化交易的品种，如果接触过Tor暗网、社工库就会明白数据能被定价流通是一件很危险的事情，若数据查询和流通方式处理不当，将是犯罪者梦寐以求的工具。

数据只有被垄断才能发挥其独有的价值，中国一直想打造以政府主导包含万物的数据库，通过制度性的信息差来“征税”，一方面能规范市场对信息的用途确保合规，这本来不是一件坏事，但政府的公权力在作怪，~~这就是政府通过权力进行经济寻租的手段，只不过手伸到了互联网行业，从而点石成金~~。

2024年1月28日补充：

> 如果要给数据确权，首先是用户使用互联网服务产生的要素成了数据，一边是服务端另一边是客户端，理应两者都共同拥有数据，理想的情况是，企业调用用户数据需要获得用户授权，用户并清楚了解授权用途、授权期限，但如今这一切都被写入不断更新的用户协议和隐私政策，而2021年颁布的《常见类型移动互联网应用程序必要个人信息范围规定》明确移动互联网应用程序（App）运营者不得因用户不同意收集非必要个人信息，而拒绝用户使用App基本功能服务。问题是该规定没有约束企业使用用户数据的用途和期限，例如是否存在假注销，数据仍保留数年之久，如今国内App都有公示必要个人信息搜集范围，但IMEI码、IP等信息都有可能是“必要”的，尤其是涉及到个性化信息服务“千人千面”，从极端的角度看，只要App通过系统底层搜集到本地log或直接破解了root权限，那以上规定就显得无力。

> 笔者认为可以直接参考欧盟的GDPR（EU General Data Protection Regulation），直接要求互联网公司对个人信息进行匿名化储存，配合积极的司法行动，参考欧洲法院重新启用欧洲共同体竞争法（European Union competition law ）“滥用市场支配地位”条款，使得互联网公司利益尽可能向社会共同利益倾斜，笔者认为通过对科技巨头进行反垄断约束，比起对数据定价更有活力，数据保护和资源配置应是渐进的。（待补充）

这种“征税”最直接的对象那就是研发大模型的企业和运用大数据割韭菜的企业，OpenAI使用别人的出版书作为训练样本而不支付著作权，如今有众多作者正对其起诉，而在中国，这钱也给不到作者手中，而是给为“数据赋值”的国家数据局，国家数据局负责确权、估值、交易，~~典型的权力怪物，很难想象能不产生寻租和贪腐~~。

## 搜索引擎污染

生成式AI直接导致了搜索引擎内容生态的污染，搜索结果却是一眼就能分辨的的AI风格回复，而且这些内容更符合搜索引擎对SEO metadata的偏好。

目前的Google对网页的爬虫还未能对AIGC生成内容进行识别判定，笔者对搜索引擎的未来是非常悲观的，一方面是私域流量的兴起，以Meta系为代表的互联网产品，把开放的互联网划分为一个个孤岛，开放信息的占比越来越小，另一方面，互联网的社会范式（social norm）式微，RSS、Atom、JSON等信息订阅方式已成为旧信息时代的产物，当前搜索引擎主要以Opengraph和JSON-LD结构化标准抓取网站内容，但这两者都很容易被生成式AI所污染。

但这其实并无解决方法，可以通过词频分析计算特异性信息，来分辨AIGC的相似度，（最近就用过知网的AIGC查重服务仍非常烂），但这样就需要对拓展SEO信息的范畴，需要将文章内容成为SEO信息的要素。

第二个方法就是像Bing Console中对主体或组织进行身份验证（测试功能），需要通过人工审查，从而优先分配权重，能有效减少内容农场和生成式AI造成的污染，百度的搜索引擎是很接近于白名单机制，理论上能在AI发展早期阻止搜索引擎的污染，可笑的是百度自家的百家号就是内容农场。

归根到底，最直接的影响是，我们以往用搜索引擎是在主动搜索原创或转载的信息，但现在搜到的有可能是通用大模型生产的“一本正经的胡说八道”文章，且混淆于原创内容的生态中。

当下或许是历史的拐点，十年后的搜索引擎可能是人与机器生成文本的交互，而不是人与人的文字的交流。

## 语言标准化

笔者试用了好久Deepl翻译和ChatGPT的润色，其内容给人的感觉非常生硬，语法上高度标准化，有时候一些细节反而歪曲了作者对原文的态度，人类语言是丰富的，带有情感的，而不是机械化的。

如果后现代审美的特征是“人为的没有深度”，那生成式AI的文本是“标准化的没有深度”。

今年阅读了不少关于AIGC生态和生成式AI的深度研报，单独的大模型不太可能是商业化成功的模板，应该是大模型+小模型有细分领域专长的，不是所有任务都需要强大的泛化、语义理解能力，其实这种文本看起来很假，是因为对于大模型。不可避免拟合主流信息，也有可能是过拟合了，而需要调整随机性，就是欠拟合的“微调”，既然如此，为何不直接为特定领域的信息构建训练集，使得大模型的参数收敛，再进行交叉检验。

目前越来越多的高等院校将生成式AI认作学术不端，笔者也不推荐使用类似Deepl的写作AI辅助工具，因为写作是一个过程，文章是自己思考过的结果，其完整性和可读性是至关重要的，我们在将思考的思绪和逻辑阐述出来，而不是三言两语发推文发朋友圈，我们要的不是类似小红书文案的主流信息，而是我思故我在，人作为主体内在的意识和反思性，这是生成式AI难以完成的推理。

始终相信人与人之间思想的交流碰撞产生思潮的力量。